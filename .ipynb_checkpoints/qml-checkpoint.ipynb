{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3253fa-49ed-4f2b-ac83-1dfcb046dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as plt2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay, RocCurveDisplay, roc_curve, plot_roc_curve, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer, AdamOptimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2604545-91e0-4046-8933-909702622f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['ID', 'Diagnosis', 'Radius', 'Texture', 'Perimeter', 'Area',\n",
    "           'Smoothness', 'Compactness', 'Concavity', 'Concave points',\n",
    "           'Symmetry', 'Fractal dimension']\n",
    "\n",
    "df = pd.read_csv('wdbc.data', index_col=0, usecols=range(12), names=columns)\n",
    "\n",
    "X = df.drop('Diagnosis', axis=1).values\n",
    "y = df['Diagnosis'].values\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "diagnoses = ['B', 'M']\n",
    "encode = {diagnoses[i]: i for i in range(len(diagnoses))}\n",
    "\n",
    "y = [encode[val] for val in y]\n",
    "for i in range(len(y)):\n",
    "    if y[i] == 0:\n",
    "        y[i] = -1\n",
    "Y = np.array(y)\n",
    "X = np.array(X)\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, y, random_state=1, test_size=0.25)\n",
    "# X_train = np.array(X_train)\n",
    "# X_test = np.array(X_test)\n",
    "# Y_train = np.array(Y_train)\n",
    "# Y_test = np.array(Y_test)\n",
    "\n",
    "# X_val = X_test\n",
    "# Y_val = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012aac99-855d-42ac-8af4-f57b49c26c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-qubit simulator.\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=2)\n",
    "\n",
    "\n",
    "def statepreparation(a):\n",
    "    for wire in range(2):\n",
    "        for i in range(len(a)):\n",
    "            qml.RY(i, wires=wire)\n",
    "\n",
    "def layer(W):\n",
    "    qml.Rot(W[0, 0], W[0, 1], W[0, 2], wires=0)\n",
    "    qml.Rot(W[1, 0], W[1, 1], W[1, 2], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# The variational classifier model and its cost remain essentially the\n",
    "# same, but we have to reload them with the new state preparation and\n",
    "# layer functions.\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(weights, features):\n",
    "    statepreparation(features)\n",
    "\n",
    "    for W in weights:\n",
    "        layer(W)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "\n",
    "def variational_classifier(weights, bias, angles):\n",
    "    return circuit(weights, angles) + bias\n",
    "\n",
    "\n",
    "def cost(weights, bias, features, labels):\n",
    "    predictions = [variational_classifier(weights, bias, f) for f in features]\n",
    "    return square_loss(labels, predictions)\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "num_data = len(y)\n",
    "num_train = int(0.75 * num_data)\n",
    "features = X\n",
    "index = np.random.permutation(range(num_data))\n",
    "feats_train = features[index[:num_train]]\n",
    "Y_train = Y[index[:num_train]]\n",
    "feats_val = features[index[num_train:]]\n",
    "Y_val = Y[index[num_train:]]\n",
    "\n",
    "# # We need these later for plotting\n",
    "X_train = X[index[:num_train]]\n",
    "X_val = X[index[num_train:]]\n",
    "\n",
    "##############################################################################\n",
    "# Optimization\n",
    "# ~~~~~~~~~~~~\n",
    "#\n",
    "# First we initialize the variables.\n",
    "\n",
    "num_qubits = 2\n",
    "num_layers = 8\n",
    "\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "opt = AdamOptimizer(0.1)\n",
    "batch_size = 8\n",
    "\n",
    "# train the variational classifier\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "for it in range(20):\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, num_train, (batch_size,))\n",
    "    feats_train_batch = feats_train[batch_index]\n",
    "    Y_train_batch = Y_train[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, feats_train_batch, Y_train_batch)\n",
    "\n",
    "    # Compute predictions on train and validation set\n",
    "    predictions_train = [np.sign(variational_classifier(weights, bias, f)) for f in feats_train]\n",
    "    predictions_val = [np.sign(variational_classifier(weights, bias, f)) for f in feats_val]\n",
    "\n",
    "    # Compute accuracy on train and validation set\n",
    "    acc_train = accuracy(Y_train, predictions_train)\n",
    "    acc_val = accuracy(Y_val, predictions_val)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Acc train: {:0.7f} | Acc validation: {:0.7f} \"\n",
    "        \"\".format(it + 1, cost(weights, bias, features, Y), acc_train, acc_val)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b5370-08e2-4b79-bd2e-36f8b3016213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3bab56-2f7c-47af-a5cb-60b831d41fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a876d34-9555-47b5-a890-eba3b88aa45f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
